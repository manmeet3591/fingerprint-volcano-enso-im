{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1104,)\n",
      "(1104,)\n",
      "(1001,)\n"
     ]
    }
   ],
   "source": [
    "nino3 = np.genfromtxt ('enso_900_2002_1.txt', delimiter=\",\")\n",
    "ismr = np.genfromtxt ('sasmi_norm_900_2002.txt', delimiter=\",\")\n",
    "vrf = np.genfromtxt ('sigl.txt', delimiter=\",\")\n",
    "print(nino3.shape)\n",
    "print(ismr.shape)\n",
    "print(vrf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110,)\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "def common_time_axis(dismr, verbose=True):\n",
    "    \"\"\"\n",
    "    Generates common time axis for Nino3 and ISMR time series.\n",
    "    \"\"\"\n",
    "    # generate the time axis\n",
    "    Nt = len(dismr)\n",
    "    time = [dt.datetime(850, 1, 15)]\n",
    "    for i in range(1, len(dismr)):\n",
    "        y = time[i - 1].year\n",
    "        m = time[i - 1].month\n",
    "        if m == 12:\n",
    "            y += 1\n",
    "            m = 0\n",
    "        time.append(dt.datetime(y, m + 1, 15))\n",
    "    time = np.array(time)\n",
    "\n",
    "    return time\n",
    "def yearly_time_axis(dvolc, verbose=True):\n",
    "    \"\"\"\n",
    "    Generates time axis for yearly data \n",
    "    \"\"\"\n",
    "    Nt = len(dvolc)\n",
    "    time = [dt.datetime(900, 1, 15)]\n",
    "    for i in range(1, len(dvolc)):\n",
    "        y = time[i - 1].year\n",
    "        y += 1\n",
    "        time.append(dt.datetime(y, 1, 15))\n",
    "    time = np.array(time)\n",
    "\n",
    "    return time\n",
    "def moving_average_anomaly(dismr,n=360):\n",
    "    \"\"\"\n",
    "    Generates moving average anomaly of long time series\n",
    "    \"\"\"\n",
    "    #print(dismr.shape)\n",
    "    dismr_anom = np.zeros((dismr.shape[0]))\n",
    "    dismr_std = np.zeros((dismr.shape[0]))\n",
    "    dismr_anom[0:n/2] = ( dismr[0:n/2] - np.mean(dismr[0:n]) )/np.std(dismr[0:n])\n",
    "    dismr_anom[dismr.shape[0]-n/2:] = ( dismr[dismr.shape[0]-n/2:] - np.mean(dismr[dismr.shape[0]-n:]) )/np.std(dismr[dismr.shape[0]-n:])\n",
    "    #print(dismr_anom)\n",
    "    dismr_std[0:n/2] = np.std(dismr[0:n])\n",
    "    dismr_std[dismr.shape[0]-n/2:] = np.std(dismr[dismr.shape[0]-n:])\n",
    "    \n",
    "    for i in range(np.int(n/2),np.int(dismr.shape[0]-n/2)):\n",
    "        dismr_anom[i] = (dismr[i] - np.mean(dismr[i-n/2:i+n/2]))/np.std(dismr[i-n/2:i+n/2])\n",
    "        dismr_std[i] = np.std(dismr[i-n/2:i+n/2])\n",
    "    return dismr_anom, dismr_std\n",
    "\n",
    "def EventSync(es1, es2, taumax):\n",
    "    \"\"\"\n",
    "    Compute non-vectorized event synchronization\n",
    "    :type es1: 1D Numpy array\n",
    "    :arg es1: Event series containing '0's and '1's\n",
    "    :type es2: 1D Numpy array\n",
    "    :arg es2: Event series containing '0's and '1's\n",
    "    :float return: Event synchronization es2 to es1\n",
    "    \"\"\"\n",
    "    ex = np.arange(len(es1))[es1 == 1]\n",
    "    ey = np.arange(len(es2))[es2 == 1]\n",
    "    lx = len(ex)\n",
    "    ly = len(ey)\n",
    "\n",
    "    count = 0\n",
    "    if lx!=0 and ly!=0:\n",
    "        for m in range(1, lx-1):\n",
    "            for n in range(1, ly-1):\n",
    "                dst = ex[m] - ey[n]\n",
    "\n",
    "                if abs(dst) > taumax:\n",
    "                    continue\n",
    "                elif dst == 0:\n",
    "                    count += 0.5\n",
    "                    continue\n",
    "\n",
    "              # finding the dynamical delay tau\n",
    "                tmp = ex[m+1] - ex[m]\n",
    "                if tmp > ex[m] - ex[m-1]:\n",
    "                    tmp = ex[m] - ex[m-1]\n",
    "                tau = ey[n+1] - ey[n]\n",
    "                if tau > ey[n] - ey[n-1]:\n",
    "                    tau = ey[n] - ey[n-1]\n",
    "                if tau > tmp:\n",
    "                    tau = tmp\n",
    "                tau = tau / 2\n",
    "\n",
    "                if dst > 0 and dst <= tau:\n",
    "                    count += 1\n",
    "\n",
    "    #print(\"count = \",count) \n",
    "    #print(\"Q = \",np.sqrt((lx-2) * (ly-2))) \n",
    "    #print(\"lx,ly,Q =\",lx,ly,count) \n",
    "    if lx!=0 and ly!=0:\n",
    "        return count / np.sqrt((lx) * (ly))\n",
    "      #return count / np.sqrt((lx-2) * (ly-2))\n",
    "    else:\n",
    "        return 0.0\n",
    "nino3_900_1850 = nino3[1:952]\n",
    "ismr_900_1850 = ismr[1:952]\n",
    "vrf_900_1850 = vrf[50:]\n",
    "#print(nino3_900_1850.shape)\n",
    "#print(vrf_900_1850.shape)\n",
    "#print(nino3_900_1850)\n",
    "year_time = yearly_time_axis(ismr_900_1850)\n",
    "volc_idx = np.where(vrf_900_1850 < -0.1)[0]\n",
    "print(volc_idx.shape)\n",
    "print(volc_idx[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "es_ismr_d = np.zeros((ismr_900_1850.shape[0]))\n",
    "es_ismr_f = np.zeros((ismr_900_1850.shape[0]))\n",
    "es_nino3_en = np.zeros((ismr_900_1850.shape[0]))\n",
    "es_nino3_ln = np.zeros((ismr_900_1850.shape[0]))\n",
    "\n",
    "es_ismr_f[ismr_900_1850>1.0] = 1.0\n",
    "es_ismr_d[ismr_900_1850<-1.0] = 1.0\n",
    "es_nino3_en[nino3_900_1850>0.5] = 1.0\n",
    "es_nino3_ln[nino3_900_1850<-0.5] = 1.0\n",
    "\n",
    "taumax = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_hist_ed = np.zeros((es_ismr_d.shape[0]-taumax))\n",
    "Q_hist_lf = np.zeros((es_ismr_d.shape[0]-taumax))\n",
    "\n",
    "for i in range(es_ismr_d.shape[0]-taumax):\n",
    "    Q_hist_12 = EventSync(es_ismr_d[i:i+taumax], es_nino3_en[i:i+taumax], taumax)\n",
    "    Q_hist_21 = EventSync(es_nino3_en[i:i+taumax], es_ismr_d[i:i+taumax],taumax)\n",
    "    Q_hist_ed[i] = Q_hist_12 + Q_hist_21\n",
    "\n",
    "    Q_hist_12 = EventSync(es_ismr_f[i:i+taumax], es_nino3_ln[i:i+taumax], taumax)\n",
    "    Q_hist_21 = EventSync(es_nino3_ln[i:i+taumax], es_ismr_f[i:i+taumax],taumax)\n",
    "    Q_hist_lf[i] = Q_hist_12 + Q_hist_21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"Q_hist_ed.csv\", Q_hist_ed, delimiter=\",\")\n",
    "np.savetxt(\"Q_hist_lf.csv\", Q_hist_lf, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.669"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1677931465378942e-05"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7958212788067276e-05"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.77536899799935022"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1770612957229076"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/iitm2/cccr-res/msingh/pmip_data_scripts/agu_volcano/event_synchronization_analysis\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
